application:
  configuration:
    ##configuration.ami: "us-west-1/ami-0e073d4b"
    configuration.datanodes_quantity: 5
    configuration.cluster_prefix: "CDH"
    configuration.cookbooks_url: "https://s3.amazonaws.com/qubell-starter-kit-artifacts/qubell-bazaar/component-hadoop-cookbooks-stable-e1a893c.tar.gz"
    configuration.repository_url: "http://archive.cloudera.com"
    configuration.cloudera_hadoop_version: "5.2.0"
    configuration.cloudera_manager_version: "5.2.0"
    configuration.cloudera_search_version: "1.3.0"
    configuration.cloudera_impala_version: "1.4.0"
    configuration.metastore_root_password: "hive"
    compute-config.hardwareId: "m3.xlarge"
    compute-config.imageId:    "ami-ee698586"
    compute-config.login:      "root"
    compute-config.locationId: "us-east-1"
    compute-datanode-config.hardwareId: "m3.large"
    compute-datanode-config.imageId:    "ami-ee698586"
    compute-datanode-config.login:      "root"
    compute-datanode-config.locationId: "us-east-1"
    
  interfaces:
    configuration:
      datanodes_quantity: "bind(cluster#configuration.quantity)"
      cluster_prefix: "bind(vms#input.cluster_prefix)"
      cookbooks_url: "bind(vms#input.cookbooks_url, cloudera-manager#configuration.cookbooks_url, cloudera-hadoop#configuration.cookbooks_url, cloudera-hive#configuration.cookbooks_url, cloudera-oozie#configuration.cookbooks_url, cloudera-impala#configuration.cookbooks_url, cloudera-sqoop#configuration.cookbooks_url, cloudera-flume#configuration.cookbooks_url, cloudera-pig#configuration.cookbooks_url, cloudera-solr#configuration.cookbooks_url, cloudera-yarn#configuration.cookbooks_url, cloudera-spark#configuration.cookbooks_url, cloudera-hue#configuration.cookbooks_url)"
      repository_url: "bind(vms#input.repository_url, cloudera-manager#configuration.repository_url, cloudera-hadoop#configuration.repository_url, cloudera-hive#configuration.repository_url, cloudera-oozie#configuration.repository_url, cloudera-impala#configuration.repository_url, cloudera-sqoop#configuration.repository_url, cloudera-flume#configuration.repository_url, cloudera-pig#configuration.repository_url, cloudera-solr#configuration.repository_url, cloudera-yarn#configuration.repository_url, cloudera-spark#configuration.repository_url, cloudera-hue#configuration.repository_url)"
      cloudera_manager_version: "bind(vms#input.cloudera_manager_version, cloudera-manager#configuration.cloudera_manager_version, cloudera-hadoop#configuration.cloudera_manager_version, cloudera-hive#configuration.cloudera_manager_version, cloudera-oozie#configuration.cloudera_manager_version, cloudera-impala#configuration.cloudera_manager_version, cloudera-sqoop#configuration.cloudera_manager_version, cloudera-solr#configuration.cloudera_manager_version, cloudera-yarn#configuration.cloudera_manager_version, cloudera-spark#configuration.cloudera_manager_version, cloudera-hue#configuration.cloudera_manager_version)"
      cloudera_hadoop_version: "bind(vms#input.cloudera_hadoop_version, cloudera-hadoop#configuration.cloudera_hadoop_version,cloudera-hive#configuration.cloudera_hadoop_version, cloudera-oozie#configuration.cloudera_hadoop_version, cloudera-impala#configuration.cloudera_hadoop_version, cloudera-sqoop#configuration.cloudera_hadoop_version, cloudera-flume#configuration.cloudera_hadoop_version, cloudera-pig#configuration.cloudera_hadoop_version, cloudera-solr#configuration.cloudera_hadoop_version, cloudera-yarn#configuration.cloudera_hadoop_version, cloudera-spark#configuration.cloudera_hadoop_version, cloudera-hue#configuration.cloudera_hadoop_version)"
      metastore_root_password: "bind(vms#input.metastore_root_password, cloudera-hive#configuration.metastore_root_password)"
      cloudera_impala_version: "bind(cloudera-impala#configuration.cloudera_impala_version)"
      cloudera_search_version: "bind(cloudera-solr#configuration.cloudera_search_version)"
    compute-config:
      hardwareId: "bind(compute-Manager#configuration.hardwareId)"
      imageId:    "bind(compute-Manager#configuration.imageId)"
      login:      "bind(compute-Manager#configuration.login)"
      locationId: "bind(compute-Manager#configuration.locationId)"
    compute-datanode-config:
      hardwareId: "bind(compute-Master#configuration.hardwareId, cluster.compute-DataNodes#configuration.hardwareId)"
      imageId:    "bind(compute-Master#configuration.imageId, cluster.compute-DataNodes#configuration.imageId)"
      login:      "bind(compute-Master#configuration.login, cluster.compute-DataNodes#configuration.login)"
      locationId: "bind(compute-Master#configuration.locationId, cluster.compute-DataNodes#configuration.locationId)"
    Cloudera:
      application-pic: "bind(metadata#output.application-pic)"
      manager: "bind(cloudera-manager#cloudera-manager.Manager_URL)"
      login: "bind(cloudera-manager#cloudera-manager.Login)"
      password: "bind(cloudera-manager#cloudera-manager.Password)"
      datanodes: "bind(vms#result.DataNodes)"
      cpu-timeseries: "bind(monitoring#result.cpu-timeseries)"
      upload-data: "bind(cloudera-hadoop#cloudera-hadoop.upload-data)"
      cleanup-data: "bind(cloudera-hadoop#cloudera-hadoop.cleanup-data)"
      run-workflow: "bind(cloudera-oozie#cloudera-oozie.run-workflow)"
  bindings:
    - [vms#compute-Master, compute-Master]
    - [vms#compute-Manager, compute-Manager]
    - [vms#compute-DataNodes, cluster.compute-DataNodes]
    - [compute-Master, cloudera-manager#compute-Master]
    - [compute-Master, cloudera-solr#compute-Master]
    - [compute-Master, cloudera-yarn#compute-Master]
    - [compute-Master, cloudera-spark#compute-Master]
    - [compute-Master, cloudera-flume#compute-Master]
    - [compute-Master, cloudera-sqoop#compute-Master]
    - [compute-Master, cloudera-impala#compute-Master]
    - [compute-Master, cloudera-hadoop#compute-Master]
    - [compute-Manager, cloudera-manager#compute-Manager]
    - [compute-Manager, cloudera-hue#compute-Manager]
    - [compute-Manager, cloudera-solr#compute-Manager]
    - [compute-Manager, cloudera-yarn#compute-Manager]
    - [compute-Manager, cloudera-spark#compute-Manager]
    - [compute-Manager, cloudera-pig#compute-Manager]
    - [compute-Manager, cloudera-flume#compute-Manager]
    - [compute-Manager, cloudera-impala#compute-Manager]
    - [compute-Manager, cloudera-hive#compute-Manager]
    - [compute-Manager, cloudera-hadoop#compute-Manager]
    - [compute-Manager, cloudera-oozie#compute-Manager]
    - [cluster.compute-DataNodes, cloudera-hadoop#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-manager#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-solr#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-yarn#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-spark#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-flume#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-impala#compute-DataNodes]
    - [cluster.compute-DataNodes, cloudera-hive#compute-DataNodes]
    - [vms, cloudera-manager]
    - [vms, cloudera-hadoop]
    - [vms, cloudera-hive]
    - [vms, cloudera-oozie]
    - [vms, cloudera-impala]
    - [vms, cloudera-sqoop]
    - [vms, cloudera-flume]
    - [vms, cloudera-pig]
    - [vms, cloudera-solr]
    - [vms, cloudera-hue]
    - [vms, cloudera-yarn]
    - [vms, cloudera-spark]
    - [cloudera-hadoop, cloudera-manager]
    - [cloudera-hive, cloudera-hadoop]
    - [cloudera-yarn, cloudera-hadoop]
    - [cloudera-spark, cloudera-yarn]
    - [cloudera-oozie, cloudera-hadoop]
    - [cloudera-impala, cloudera-hive]
    - [cloudera-sqoop, cloudera-hadoop]
    - [cloudera-flume, cloudera-hadoop]
    - [cloudera-pig, cloudera-flume]
    - [cloudera-solr, cloudera-hadoop]
    - [cloudera-hue, cloudera-impala]
    - [cloudera-hue, cloudera-sqoop]
    - [cloudera-hue, cloudera-solr]
    - [monitoring, compute-Manager]
    - [monitoring, vms]
    - [monitoring, cloudera-manager]
    - [monitoring, cloudera-hue]
  components:
    metadata:
      type: cobalt.common.Constants
      interfaces:
        output:
          application-pic:
            type: publish-signal(map<string, object>)
            name: ""
      configuration:
        configuration.values:
          output.application-pic:
            large: "https://s3.amazonaws.com/qubell-images/hadoop.png"
            small: "https://s3.amazonaws.com/qubell-images/hadoop_med.png"
            small-height: 64
    monitoring:
      type: workflow.Instance
      required: [ vms, cloudera-hue, cloudera-manager ]
      interfaces:
        cloudera-hue:
          hue_url: consume-signal(list<string>)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-manager:
          Manager_URL: consume-signal(string)
          Login: consume-signal(string)
          Password: consume-signal(string)
        result:
          cpu-timeseries:
            type: publish-signal(map<string, list<object>>)
            name: CPU usage
      configuration:
        configuration.triggers: {}
        configuration.schedule:
          update: "0 0/5 * * * ? *"
        configuration.workflows:
          launch: &launch
            steps:
              - getSignals:
                  action: getSignals
                  output:
                    signals: result
              - getCpu:
                  action: restcall
                  precedingPhases: [ getSignals ]
                  parameters:
                    command: "http://{$.signals.compute-Manager.networks.public.ip}:7180/api/v4/timeseries?query=select+cpu_percent_across_hosts+where+category+%3D+CLUSTER"
                    method: GET
                    auth:
                      type: basic
                      user: "{$.signals.cloudera-manager.Login}"
                      password: "{$.signals.cloudera-manager.Password}"
                    contentType: application/json
                  output:
                    cpu: content
            return:
              cpu-timeseries:
                description: "CPU graph"
                value: "{$.cpu}"
          update: *launch

    compute-Master:
      type: compute.Instance
    compute-Manager:
      type: compute.Instance
    cluster:
      type: composite.Scaler
      components:
        compute-DataNodes:
          type: compute.Instance

    vms:
      type: workflow.Instance
      interfaces:
        input:
          #  type: configuration(map<string,object>)
          #  suggestions:
          #    east: {image: "us-east-1/ami-ee698586", identity: "root"}
          #    west: {image: "us-west-1/ami-0e073d4b", identity: "root"}
          cluster_prefix:
            type: configuration(string)
            name: EC2 node name prefix
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
          metastore_root_password:
            type: configuration(string)
            name: MetaStore root password
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        result:
          Node_Manager_DNS:
            type: publish-signal(string)
            name: Manager node DNS
          Node_Master_DNS:
            type: publish-signal(string)
            name: Master node DNS
          DataNodesDNS:
            type: publish-signal(list<string>)
            name: Data nodes DNS
          DataNodes:
            type: publish-signal(list<string>)
            name: Data nodes
      required: [ compute-Master, compute-Manager, compute-DataNodes ]
      configuration:
        configuration.triggers: {}
        configuration.workflows:
          launch:
            steps:
              - waitPeers:
                   action: waitPeers
                   parameters:
                     interfaces:
                       compute-DataNodes: 5
                     timeout:
                       10 minute
              - get-signals:
                  action: getSignals
                  precedingPhases: [ waitPeers ]
                  parameters:
                    multi: true
                  output:
                    signals: result
              - provision-hadoop-manager:
                  action: .provision-node
                  phase: provision-node
                  precedingPhases: [ get-signals ]
                  parameters:
                      roleName: "compute-Manager"
                  output:
                      managerDns: dns
              - provision-hadoop-master:
                  action: .provision-node
                  phase: provision-node
                  precedingPhases: [ get-signals ]
                  parameters:
                      roleName: "compute-Master"
                  output:
                      masterDns: dns
              - provision-datanode:
                  action: .provision-node
                  phase: provision-node
                  precedingPhases: [ get-signals ]
                  parameters:
                      roleName: "compute-DataNodes"
                  output:
                      datanodeDns: dns
              - update-hosts:
                  action: chefrun
                  phase: update-hosts
                  precedingPhases: [ provision-node ]
                  parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "compute-DataNodes", "compute-Manager", "compute-Master" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::hosts_aws]" ]
                      jattrs:
                          base:
                              hosts_aws: [ "{$.masterDns[*]}", "{$.managerDns[*]}", "{$.datanodeDns[*]}" ]
              - install-pkgs-on-all-nodes:
                  action: chefrun
                  precedingPhases: [ update-hosts ]
                  parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "compute-DataNodes", "compute-Manager", "compute-Master" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::install_pkgs]", ]
                      jattrs:
                        java:
                          java_home: "/usr/java/jdk6"
                        cloudera:
                          master:
                            host: "{$.masterDns[*][0]}"
                          manager:
                            host: "{$.managerDns[*][0]}"
                            version: "{$.cloudera_manager_version}"
                          datanodes:
                            hosts: "{$.datanodeDns[*]}"
                          hadoop:
                            version: "{$.cloudera_hadoop_version}"
                          repository_url: "{$.repository_url}"
              - install-pkgs-on-manager:
                  action: chefrun
                  precedingPhases: [ install-pkgs-on-all-nodes ]
                  parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "compute-Manager" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::install_pkgs_manager]", ]
                      jattrs:
                        java:
                          java_home: "/usr/java/jdk6"
                        cloudera:
                          master:
                            host: "{$.masterDns[*][0]}"
                          manager:
                            host: "{$.managerDns[*][0]}"
                            version: "{$.cloudera_manager_version}"
                          jobtracker:
                            host: "{$.managerDns[*][0]}"
                            ip: "{$.signals.compute-Manager.*.networks.public.ip}"
                          datanodes:
                            hosts: "{$.datanodeDns[*]}"
                          hadoop:
                            version: "{$.cloudera_hadoop_version}"
                          repository_url: "{$.repository_url}"
                        mysql:
                          server_debian_password: "{$.metastore_root_password}"
                          server_root_password: "{$.metastore_root_password}"
                          server_repl_password: "{$.metastore_root_password}"
                          bind_address: "127.0.0.1"
                          
              - install-pkgs-on-master-datanodes:
                  action: chefrun 
                  precedingPhases: [ install-pkgs-on-all-nodes ]
                  parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "compute-DataNodes", "compute-Master" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::install_pkgs_master_datanodes]", ]
                      jattrs:
                        java:
                          java_home: "/usr/java/jdk6"
                        cloudera:
                          master:
                            host: "{$.masterDns[*][0]}"
                          manager:
                            host: "{$.managerDns[*][0]}"
                            version: "{$.cloudera_manager_version}"
                          datanodes:
                            hosts: "{$.datanodeDns[*]}"
                          hadoop:
                            version: "{$.cloudera_hadoop_version}"
                          repository_url: "{$.repository_url}"
              - install-pkgs-on-master:
                  action: chefrun
                  precedingPhases: [ install-pkgs-on-master-datanodes ]
                  parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "compute-Master" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::install_pkgs_master]", ]
                      jattrs:
                        java:
                          java_home: "/usr/java/jdk6"
                        cloudera:
                          master:
                            host: "{$.masterDns[*][0]}"
                          manager:
                            host: "{$.managerDns[*][0]}"
                            version: "{$.cloudera_manager_version}"
                          datanodes:
                            hosts: "{$.datanodeDns[*]}"
                          hadoop:
                            version: "{$.cloudera_hadoop_version}"
                          repository_url: "{$.repository_url}"
                
            return:
              - Node_Manager_DNS:
                  value: "{$.managerDns[*][0]}"
              - Node_Master_DNS:
                  value: "{$.masterDns[*][0]}"
              - DataNodesDNS:
                  value: "{$.datanodeDns[*]}"
              - DataNodes:
                  value: "{$.signals.compute-DataNodes.*.networks.public.ip}"

          .provision-node:
              parameters:
                - roleName:
                    description: Role for the provisioned node
              steps:
                - link-folders:
                    action: execrun
                    parameters:
                      isSudo: true
                      roles: [ "{$.roleName}" ]
                      command:
                          - bash
                          - "-c"
                          - |
                                mkdir -p /srv &&
                                mkdir -p /opt/srv &&
                                mkdir -p /opt/tmp &&
                                mkdir -p /opt/log &&
                                mkdir -p /opt/tmp/debug &&
                                chmod -R 777 /opt/srv &&
                                chmod -R 777 /opt/tmp &&
                                mount --bind /opt/tmp /tmp &&
                                mount --bind /opt/srv /srv &&
                                ln -s /opt/tmp/debug /usr/lib/debug
                - set-hostname:
                    action: execrun
                    phase: post-provision
                    precedingPhases: [ link-folders ]
                    parameters:
                      isSudo: true
                      roles: [ "{$.roleName}" ]
                      command:
                          - bash
                          - "-c"
                          - |
                                hostname `curl -s http://169.254.169.254/latest/meta-data/public-hostname` &&
                                echo "`hostname -i`   `hostname`" >> /etc/hosts &&
                                hostname
                    output:
                      dns: stdout
                - install-ntp:
                    action: chefrun
                    phase: post-provision
                    precedingPhases: [ link-folders ]
                    parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "{$.roleName}" ]
                      runList: ["recipe[ntp]"]
                      recipeUrl: "{$.cookbooks_url}"
                      jattrs:
                        ntp:
                          servers: ["0.amazon.pool.ntp.org"]
                - install-ephemeral:
                    action: chefrun
                    phase: install-ephemeral
                    precedingPhases: [ post-provision ]
                    parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "{$.roleName}" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[cloudera::ephemeral]" ]
                - install-java:
                    action: chefrun
                    precedingPhases: [ install-ephemeral ]
                    parameters:
                      isSudo: true
                      isSolo: true
                      roles: ["{$.roleName}"]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[java]" ]
                      jattrs:
                        java:
                          install_flavor: "oracle"
                          jdk_version: "6"
                          java_home: "/usr/java/jdk6"
                          oracle:
                            accept_oracle_download_terms: "true"
                - install-mysql-client:
                    action: chefrun
                    precedingPhases: [install-java]
                    parameters:
                      isSudo: true
                      isSolo: true
                      roles: [ "{$.roleName}" ]
                      recipeUrl: "{$.cookbooks_url}"
                      runList: [ "recipe[mysql::client]" ]
                - disable-iptables:
                    action: execrun
                    precedingPhases: [ install-java ]
                    parameters:
                      isSudo: true
                      roles: [ "{$.roleName}" ]
                      command:
                          - bash
                          - "-c"
                          - |
                                /etc/init.d/iptables stop
              return:
                dns:
                  value: "{$.dns}"
    cloudera-manager:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Manager"
      required: [vms, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-manager:
          Manager_URL:
            type: publish-signal(string)
            name: Manager URL
          Login:
            type: publish-signal(string)
            name: Login
          Password:
            type: publish-signal(string)
            name: Password
    cloudera-hadoop:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Hadoop"
      required: [vms, cloudera-manager, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-manager:
          Manager_URL: consume-signal(string)
          Login: consume-signal(string)
          Password: consume-signal(string)
        cloudera-hadoop:
          NameNode:
            type: publish-signal(list<string>)
            name: Default Namenode
          Primary_NameNode:
            type: publish-signal(list<string>)
            name: Primary Namenode
          Secondary_NameNode:
            type: publish-signal(list<string>)
            name: Secondary Namenode
          Hbase_Master:
            type: publish-signal(list<string>)
            name: HBase master server
          Hbase_MasterDns:
            type: publish-signal(string)
            name: HBase master server DNS
          JobTracker:
            type: publish-signal(list<string>)
            name: Jobtracker node
          cloudera_hdfsWebui:
            type: publish-signal(list<string>)
            name: HDFS web UI
          cloudera_jobtrackerWebui:
            type: publish-signal(list<string>)
            name: Jobtracker web UI
          cloudera_hbaseWebui:
            type: publish-signal(list<string>)
            name: HBase web UI
          upload-data:
            type: receive-command(string archive-url => string data-dir, string data-url)
            name: Upload data
          cleanup-data:
            type: receive-command(string data-dir)
            name: Cleanup data
    cloudera-hive:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Hive"
      required: [vms, cloudera-hadoop, compute-Manager, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
          metastore_root_password:
            type: configuration(string)
            name: MetaStore root password
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-hive:
          Hive_Server:
            type: publish-signal(list<string>)
            name: Hive server
          Hive_Metastore:
            type: publish-signal(list<string>)
            name: Hive MetaStore server
    cloudera-oozie:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Oozie"
      required: [vms, cloudera-hadoop, compute-Manager]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-oozie:
          Oozie_Server:
            type: publish-signal(list<string>)
            name: Oozie server
          run-workflow:
            type: receive-command(string archive-url, string data-dir => string status)
            name: Run workflow
    cloudera-impala:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Impala"
      required: [vms, cloudera-hive, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
          cloudera_impala_version:
            type: configuration(string)
            name: Cloudera Impala version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hive:
          Hive_Server: consume-signal(list<string>)
          Hive_Metastore: consume-signal(list<string>)
        cloudera-impala:
          Impala_Master:
            type: publish-signal(list<string>)
            name: Impala master server
    cloudera-sqoop:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Sqoop"
      required: [vms, cloudera-hadoop, compute-Master]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-sqoop:
          Sqoop_Master:
            type: publish-signal(list<string>)
            name: Sqoop master server
    cloudera-flume:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Flume"
      required: [vms, cloudera-hadoop, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-flume:
          Flume_Status:
            type: publish-signal(string)
            name: Flume application status
    cloudera-pig:
      type: reference.Submodule
      configuration:
       __locator.application-id: "Cloudera Pig"
      required: [vms, cloudera-flume, compute-Manager]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-flume:
          Flume_Status: consume-signal(string)
        cloudera-pig:
          Pig_Status:
            type: publish-signal(string)
            name: Pig application status
    cloudera-solr:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Solr"
      required: [vms, cloudera-hadoop, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
          cloudera_search_version:
            type: configuration(string)
            name: Cloudera Search version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-solr:
          Solr_Uri:
            type: publish-signal(list<string>)
            name: Solr connection string
    cloudera-yarn:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Yarn"
      required: [vms, cloudera-hadoop, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-hadoop:
          NameNode: consume-signal(list<string>)
          Primary_NameNode: consume-signal(list<string>)
          Secondary_NameNode: consume-signal(list<string>)
          Hbase_Master: consume-signal(list<string>)
          Hbase_MasterDns: consume-signal(string)
          JobTracker: consume-signal(list<string>)
          cloudera_hdfsWebui: consume-signal(list<string>)
          cloudera_jobtrackerWebui: consume-signal(list<string>)
          cloudera_hbaseWebui: consume-signal(list<string>)
        cloudera-yarn:
          Resource_Manager_Uri:
            type: publish-signal(string)
            name: Yarn Resource Manager
          Job_History_Uri:
            type: publish-signal(string)
            name: Yarn Job History
    cloudera-spark:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Spark"
      required: [vms, cloudera-yarn, compute-Manager, compute-Master, compute-DataNodes]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Master:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        compute-DataNodes:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-yarn:
          Resource_Manager_Uri:
            type: consume-signal(string)
            name: Yarn Resource_Manager_Uri
          Job_History_Uri:
            type: consume-signal(string)
            name: Yarn Job_History_Uri
        cloudera-spark:
          Spark_History_Uri:
            type: publish-signal(string)
            name: Yarn Job_History_Uri
        
    cloudera-hue:
      type: reference.Submodule
      configuration:
        __locator.application-id: "Cloudera Hue"
      required: [vms, cloudera-solr, cloudera-impala, cloudera-sqoop, compute-Manager]
      interfaces:
        configuration:
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        compute-Manager:
          networks:        consume-signal(map<string, map<string, string>>)
          exec:            send-command(string command, int timeout => string stdOut, string stdErr => string stdOut, string stdErr, int exitCode)
          put-file:        send-command(string filename, bytes payload)
          get-file:        send-command(string filename => bytes payload)
        vms:
          Node_Manager_DNS: consume-signal(string)
          Node_Master_DNS: consume-signal(string)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-impala:
          Impala_Master: consume-signal(list<string>)
        cloudera-sqoop:
          Sqoop_Master: consume-signal(list<string>)
        cloudera-solr:
          Solr_Uri: consume-signal(list<string>)
        cloudera-hue:
          hue_url:
            type: publish-signal(list<string>)
            name: Hue web UI
